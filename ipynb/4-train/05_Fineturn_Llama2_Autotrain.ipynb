{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autotrain 을 가지고 Llama2 데이터 학습 : PEFT\n",
    "    * Autotrain 을 로컬데이터를 학습할 수 있는 방법을 찾지 못함.\n",
    "    * 허깅페이스의 자원을 이용해서 모델학습을 시켜야 함.\n",
    "```\n",
    "1. excute: https://www.inflearn.com/course/lecture?courseSlug=%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8-llm-part1&unitId=178421\n",
    "2. model: Llama2 pytouch.bin\n",
    "3. parameter data type: touch.float16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### requiment modules\n",
    "```\n",
    "pip install autotrain-advanced\n",
    "pip install transformers\n",
    "pip install bitsandbytes\n",
    "pip install accelerate\n",
    "pip install sentencepiece\n",
    "pip install protobuf\n",
    "pip install xformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotrain 라이브러리 설치\n",
    "%pip install autotrain-advanced -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotrain 라이브러리 업데이트\n",
    "!autotrain setup --update-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 위한 환경 변수 설정\n",
    "import os\n",
    "os.environ[\"PROJECT_NAME\"] = \"kocasalpha-sllm7b\"\n",
    "os.environ[\"MODEL_NAME\"] = \"/data/aibiseo/models/casllm-base-7b-hf\"\n",
    "os.environ[\"DATA_PATH\"] = \"/data/aibiseo/dataset/alpaca_en_dataset.jsonl\"\n",
    "os.environ[\"TEXT_COLUMN\"] = \"text\"\n",
    "os.environ[\"QUANTIZATION\"] = \"int4\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk(\"/data/aibiseo/dataset/alpaca_en_dataset.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': ['<s>[INST] Give three tips for staying healthy. [/INST] [REF]  [/REF] 1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule. </s>',\n",
       "  '<s>[INST] What are the three primary colors? [/INST] [REF]  [/REF] The three primary colors are red, blue, and yellow. </s>',\n",
       "  '<s>[INST] Describe the structure of an atom. [/INST] [REF]  [/REF] An atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom. </s>',\n",
       "  '<s>[INST] How can we reduce air pollution? [/INST] [REF]  [/REF] There are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances. </s>',\n",
       "  '<s>[INST] Describe a time when you had to make a difficult decision. [/INST] [REF]  [/REF] I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities. </s>']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1mINFO    Running LLM\u001b[0m\n",
      "> \u001b[1mINFO    Params: Namespace(version=False, text_column='dataset', rejected_text_column='rejected', prompt_text_column='prompt', model_ref=None, warmup_ratio=0.1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, add_eos_token=False, block_size=4096, peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=True, mixed_precision=None, quantization='int4', model_max_length=4096, trainer='sft', target_modules=None, merge_adapter=False, use_flash_attention_2=False, dpo_beta=0.1, chat_template=None, padding=None, train=True, deploy=False, inference=False, username=None, backend='local-cli', token=None, repo_id=None, push_to_hub=False, model='/data/aibiseo/models/casllm-base-7b-hf', project_name='/data/aibiseo/models/kocasalpha-sllm7b', seed=42, epochs=1, gradient_accumulation=1, disable_gradient_checkpointing=False, lr=0.0002, log='none', data_path='/data/aibiseo/dataset/alpaca_en_dataset.jsonl', train_split='train', valid_split=None, batch_size=2, func=<function run_llm_command_factory at 0x7f3e9cb69120>)\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/pvenv/train/bin/autotrain\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/data/pvenv/train/lib/python3.10/site-packages/autotrain/cli/autotrain.py\", line 50, in main\n",
      "    command.run()\n",
      "  File \"/data/pvenv/train/lib/python3.10/site-packages/autotrain/cli/run_llm.py\", line 332, in run\n",
      "    params = LLMTrainingParams(\n",
      "  File \"/data/pvenv/train/lib/python3.10/site-packages/autotrain/trainers/common.py\", line 133, in __init__\n",
      "    raise ValueError(\"project_name must be alphanumeric but can contain hyphens\")\n",
      "ValueError: project_name must be alphanumeric but can contain hyphens\n"
     ]
    }
   ],
   "source": [
    "!autotrain llm --train \\\n",
    "    --project-name \"/data/aibiseo/models/kocasalpha-sllm7b\" \\\n",
    "    --model \"/data/aibiseo/models/casllm-base-7b-hf\" \\\n",
    "    --data-path \"/data/aibiseo/dataset/alpaca_en_dataset.jsonl\" \\\n",
    "    --text_column \"dataset\" \\\n",
    "    --peft\\\n",
    "    --quantization \"int4\"\\\n",
    "    --lr 2e-4 \\\n",
    "    --auto-find-batch-size \\\n",
    "    --epochs 1 \\\n",
    "    --trainer sft \\\n",
    "    --block_size 4096 \\\n",
    "    --model_max_length 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain llm --train \\\n",
    "    --project-name \"kocasalpha-sllm7b\" \\\n",
    "    --model \"/data/aibiseo/models/casllm-base-7b-hf\" \\\n",
    "    --data-path \"/data/aibiseo/dataset/alpaca_en_dataset.jsonl\" \\\n",
    "    --text-column \"text\" \\\n",
    "    --peft \\\n",
    "    --quantization \"int4\"\\\n",
    "    --lora-r 16 \\\n",
    "    --lr 2e-4 \\\n",
    "    --auto-find-batch-size \\\n",
    "    --epochs 1 \\\n",
    "    --trainer sft \\\n",
    "    --block_size 4096 \\\n",
    "    --model_max_length 4096"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

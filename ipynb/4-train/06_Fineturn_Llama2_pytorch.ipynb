{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autotrain 을 가지고 Llama2 데이터 학습 : PEFT\n",
    "    * Autotrain 을 로컬데이터를 학습할 수 있는 방법을 찾지 못함.\n",
    "    * 허깅페이스의 자원을 이용해서 모델학습을 시켜야 함.\n",
    "```\n",
    "1. excute: https://hackernoon.com/ko/%EC%A7%91%EC%97%90%EC%84%9C-%EB%A7%8C%EB%93%A0-%EB%8C%80%ED%98%95-%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8%EC%9D%84-%EC%8B%A4%ED%97%98%ED%95%98%EB%8A%94-%EC%95%8C%ED%8C%8C%EC%B9%B4-%EB%A1%9C%EB%9D%BC\n",
    "2. model: Llama2 pytouch.bin\n",
    "3. parameter data type: touch.float16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### requiment modules\n",
    "```\n",
    "pip install autotrain-advanced\n",
    "pip install transformers\n",
    "pip install bitsandbytes\n",
    "pip install accelerate\n",
    "pip install sentencepiece\n",
    "pip install protobuf\n",
    "pip install xformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotrain 라이브러리 설치\n",
    "%pip install autotrain-advanced -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotrain 라이브러리 업데이트\n",
    "!autotrain setup --update-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 위한 환경 변수 설정\n",
    "import os\n",
    "os.environ[\"PROJECT_NAME\"] = \"kocasalpha-sllm7b\"\n",
    "os.environ[\"MODEL_NAME\"] = \"/data/aibiseo/models/casllm-base-7b-hf\"\n",
    "os.environ[\"DATA_PATH\"] = \"/data/aibiseo/dataset/alpaca_en_dataset.jsonl\"\n",
    "os.environ[\"TEXT_COLUMN\"] = \"text\"\n",
    "os.environ[\"QUANTIZATION\"] = \"int4\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk(\"/data/aibiseo/dataset/alpaca_en_dataset.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works on A100 80G x4\n",
    "!torchrun --nproc_per_node=4 --master_port=34321 ../script/train/run_clm.py \\\n",
    "--model_name_or_path='/data/aibiseo/models/casllm-base-7b-hf' \\\n",
    "--train_file='/data/aibiseo/dataset/en_alpaca_data.json' \\\n",
    "--num_train_epochs=2 \\\n",
    "--block_size=1024 \\\n",
    "--per_device_train_batch_size=1 \\\n",
    "--gradient_accumulation_steps=64 \\\n",
    "--torch_dtype=float16 \\\n",
    "--fp16 \\\n",
    "--output_dir='/data/aibiseo/models/kocasalpha-sllm7b' \\\n",
    "--deepspeed=ds_zero3-nooffload.json \\\n",
    "--do_train \\\n",
    "--save_strategy='epoch' \\\n",
    "--logging_strategy='steps' \\\n",
    "--logging_first_step \\\n",
    "--save_total_limit=1 \\\n",
    "--run_name='polyglot-12.8b-koalpaca-v1.1b-ga64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain llm --train \\\n",
    "    --project-name \"/data/aibiseo/models/kocasalpha-sllm7b\" \\\n",
    "    --model \"/data/aibiseo/models/casllm-base-7b-hf\" \\\n",
    "    --data-path \"/data/aibiseo/dataset/alpaca_en_dataset.jsonl\" \\\n",
    "    --text_column \"dataset\" \\\n",
    "    --peft\\\n",
    "    --quantization \"int4\"\\\n",
    "    --lr 2e-4 \\\n",
    "    --auto-find-batch-size \\\n",
    "    --epochs 1 \\\n",
    "    --trainer sft \\\n",
    "    --block_size 4096 \\\n",
    "    --model_max_length 4096"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

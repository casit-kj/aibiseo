{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Llama2 모델 학습\n",
    "   > ##### AutoTrain 을 사용\n",
    "   \n",
    "1. python module 설치\n",
    "   * %pip install torch fairscale fire sentencepiece transformers protobuf accelerate peft bitsandbytes trl\\\n",
    "   * %pip install accelerate==0.26.1 peft==0.8.2 bitsandbytes==0.42.0 transformers==4.37.2 trl==0.7.10 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch fairscale fire sentencepiece transformers protobuf accelerate peft bitsandbytes trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_datset = \"/data/aibiseo/dataset\"\n",
    "json_filename = \"en_alpaca_data.json\"\n",
    "json_file_path = os.path.join(dir_datset,json_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face Basic Model 한국어 기본모델\n",
    "model_id = \"/data/aibiseo/models/casllm-base-7b-hf\"\n",
    "\n",
    "# Custom Dataset ★ 저장한 모델경로를 설정 ★\n",
    "hkcode_dataset = \"/data/aibiseo/models/\"\n",
    "\n",
    "# Fine-tuned model\n",
    "fineturn_model_id = \"casllm-audit-7bhr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PROJECT_NAME\"] = project_name\n",
    "os.environ[\"MODEL_NAME\"] = model_name\n",
    "#os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
    "#os.environ[\"HF_TOKEN\"] = hf_token\n",
    "#os.environ[\"REPO_ID\"] = repo_id\n",
    "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
    "os.environ[\"NUM_EPOCHS\"] = str(num_epochs)\n",
    "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
    "os.environ[\"BLOCK_SIZE\"] = str(block_size)\n",
    "os.environ[\"WARMUP_RATIO\"] = str(warmup_ratio)\n",
    "os.environ[\"WEIGHT_DECAY\"] = str(weight_decay)\n",
    "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
    "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
    "os.environ[\"USE_PEFT\"] = str(use_peft)\n",
    "os.environ[\"QIAMTOZATION\"] = quantization\n",
    "os.environ[\"LORA_R\"] = str(lora_r)\n",
    "os.environ[\"LORA_ALPHA\"] = str(lora_alpha)\n",
    "os.environ[\"LORA_DROPOUT\"] = str(lora_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain llm \\\n",
    "--train \\\n",
    "--model ${MODEL_NAME} \\\n",
    "--project-name ${PROJECT_NAME} \\\n",
    "--data-path data/ \\\n",
    "--text-column text \\\n",
    "--lr ${LEARNING_RATE} \\\n",
    "--batch-size ${BATCH_SIZE} \\\n",
    "--epochs ${NUM_EPOCHS} \\\n",
    "--block-size ${BLOCK_SIZE} \\\n",
    "--warmup-ratio ${WARMUP_RATIO} \\\n",
    "--lora-r ${LORA_R} \\\n",
    "--lora-alpha ${LORA_ALPHA} \\\n",
    "--lora-dropout ${LORA_DROPOUT} \\\n",
    "--weight-decay ${WEIGHT_DECAY} \\\n",
    "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
    "--mixed-precision ${MIXED_PRECISION} \\\n",
    "$( [[ \"$USE_PEFT\" == \"True\" ]] && echo \"--peft\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 작업 완료 : 100%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

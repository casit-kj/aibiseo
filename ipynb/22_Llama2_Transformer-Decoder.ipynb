{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Llama2 Transformer-Decoder : 문장 생성\n",
    "* Original Llama2 모델을 [11_라마2허깅페이스_변환] 방법을 사용해 변환모델을 로드하여 문장을 생성한다.\n",
    "* 문장 생성을 위한 transformer 객체 : LlamaForCausalLM\n",
    "* 모델이름: casllm-base-7b-hf\n",
    "* [참고] https://huggingface.co/docs/transformers/main/en/model_doc/llama2#transformers.LlamaModel\n",
    "\n",
    "1. 토큰라이저 할당\n",
    "2. 모델 할당\n",
    "3. 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "model_id = \"/data/bwllm/models/casllm-base-7b-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(model_id)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM과 대화\n",
    "    1. prompt 설정\n",
    "    2. 토큰라이저를 사용해 질문을 토큰으로 변환\n",
    "    3. 임베딩 토큰 문장 생성(encoding)\n",
    "    4. 토큰 문장을 디코딩하여 텍스트 문장으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hey, are you conscious? Can you talk to me?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "print(generate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(generate_ids[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문장 생성 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 문장 생성 옵션들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"안녕!! 한국어 할 줄 아니?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ids = model.generate(**inputs, max_length=50, temperature=0.7, num_return_sequences=1)\n",
    "print(generate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(generate_ids[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casllm",
   "language": "python",
   "name": "casllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
